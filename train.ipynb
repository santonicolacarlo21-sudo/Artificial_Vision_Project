{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-09T10:48:49.411603Z",
     "iopub.status.busy": "2024-02-09T10:48:49.411063Z",
     "iopub.status.idle": "2024-02-09T10:48:50.372643Z",
     "shell.execute_reply": "2024-02-09T10:48:50.371373Z",
     "shell.execute_reply.started": "2024-02-09T10:48:49.411570Z"
    },
    "executionInfo": {
     "elapsed": 6720,
     "status": "ok",
     "timestamp": 1706872186143,
     "user": {
      "displayName": "LORENZO MIGNONE",
      "userId": "02647048791547825809"
     },
     "user_tz": -60
    },
    "id": "BFJRTnFG5YBz",
    "outputId": "9b69f502-23a5-498d-d240-80e364f785c0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "global device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.empty_cache()\n",
    "  print(\"You have %d GPUs\" % torch.cuda.device_count())\n",
    "\n",
    "gc.isenabled()\n",
    "!mkdir -p /kaggle/working/par_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-09T10:49:01.884955Z",
     "iopub.status.busy": "2024-02-09T10:49:01.884021Z",
     "iopub.status.idle": "2024-02-09T10:49:07.381200Z",
     "shell.execute_reply": "2024-02-09T10:49:07.380221Z",
     "shell.execute_reply.started": "2024-02-09T10:49:01.884911Z"
    },
    "executionInfo": {
     "elapsed": 70179,
     "status": "ok",
     "timestamp": 1706872260216,
     "user": {
      "displayName": "LORENZO MIGNONE",
      "userId": "02647048791547825809"
     },
     "user_tz": -60
    },
    "id": "b3a-u-mh5YB0",
    "outputId": "e6c309bd-7b5a-43fe-b742-a5473be4ed4f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "\n",
    "def extract_annotation(label_path):\n",
    "  annotations_list = []\n",
    "\n",
    "  with open(label_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        \n",
    "        line = line.strip()\n",
    "        elements = line.split(',')\n",
    "        \n",
    "        colours = [int(e)-1 if int(e) != -1 else int(e) for e in elements[1:3]]\n",
    "        \n",
    "        annotation_tuple = (\n",
    "            elements[0],  \n",
    "            int(colours[0]), \n",
    "            int(colours[1]), \n",
    "            int(elements[3]),  \n",
    "            int(elements[4]),  \n",
    "            int(elements[5])  \n",
    "        )\n",
    "        \n",
    "        annotations_list.append(annotation_tuple)\n",
    "\n",
    "  annotations_list.sort(key=lambda x: x[0])\n",
    "  return annotations_list\n",
    "\n",
    "training_folder = '/kaggle/input/par-dataset/training_set/training_set'\n",
    "validation_folder = '/kaggle/input/par-dataset/validation_set/validation_set'\n",
    "\n",
    "train_label = '/kaggle/input/par-dataset/training_set(1).txt'\n",
    "validation_label = '/kaggle/input/par-dataset/validation_set.txt'\n",
    "\n",
    "annotations_training_list = extract_annotation(train_label)\n",
    "annotations_validation_list = extract_annotation(validation_label)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),\n",
    "        transforms.RandomAffine(degrees=30, shear=10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "training_image_paths = [os.path.join(training_folder, filename) for filename in os.listdir(training_folder)]\n",
    "validation_image_paths = [os.path.join(validation_folder, filename) for filename in os.listdir(validation_folder)]\n",
    "\n",
    "\n",
    "training_image_paths.sort()\n",
    "validation_image_paths.sort()\n",
    "\n",
    "print(len(training_image_paths))\n",
    "print(len(validation_image_paths))\n",
    "print(len(annotations_training_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T10:49:14.975357Z",
     "iopub.status.busy": "2024-02-09T10:49:14.974985Z",
     "iopub.status.idle": "2024-02-09T10:49:15.006652Z",
     "shell.execute_reply": "2024-02-09T10:49:15.005790Z",
     "shell.execute_reply.started": "2024-02-09T10:49:14.975328Z"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1706784494057,
     "user": {
      "displayName": "LORENZO MIGNONE",
      "userId": "02647048791547825809"
     },
     "user_tz": -60
    },
    "id": "d_zYWl7Z5YB1",
    "outputId": "59401501-b1b3-4458-8c1f-181b94583637",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels    # lista di tuple (nome, att1, att2, att3, att4, att5)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        global device\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        label = torch.tensor(list(label[1:])).to(device)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    @staticmethod\n",
    "    def make_weights(dataset):\n",
    "        global device\n",
    "        upper_dict = defaultdict(int)  \n",
    "        lower_dict = defaultdict(int)\n",
    "        gender_dict = defaultdict(int)\n",
    "        bag_dict = defaultdict(int)\n",
    "        hat_dict = defaultdict(int)\n",
    "\n",
    "        for label in dataset.labels:\n",
    "            upper = label[1]\n",
    "            lower = label[2]\n",
    "            gender = label[3]\n",
    "            bag = label[4]\n",
    "            hat = label[5]\n",
    "\n",
    "            if upper != -1:\n",
    "                upper_dict[upper] += 1\n",
    "\n",
    "            if lower != -1:\n",
    "                lower_dict[lower] += 1\n",
    "            \n",
    "            if gender != -1:\n",
    "                gender_dict[gender] += 1\n",
    "            \n",
    "            if bag != -1:\n",
    "                bag_dict[bag] += 1\n",
    "            \n",
    "            if hat != -1:\n",
    "                hat_dict[hat] += 1\n",
    "\n",
    "        key_upper = list(upper_dict.keys())\n",
    "        key_lower = list(lower_dict.keys())\n",
    "        key_gender = list(gender_dict.keys())\n",
    "        key_bag = list(bag_dict.keys())\n",
    "        key_hat = list(hat_dict.keys())\n",
    "\n",
    "        key_upper = sorted(key_upper)\n",
    "        key_lower = sorted(key_lower)\n",
    "        key_gender = sorted(key_gender)\n",
    "        key_bag = sorted(key_bag)\n",
    "        key_hat = sorted(key_hat)\n",
    "\n",
    "        upper_weights = torch.tensor([1 / upper_dict[key] for key in key_upper]).to(device)\n",
    "        lower_weights = torch.tensor([1 / lower_dict[key] for key in key_lower]).to(device)\n",
    "        gender_weights = torch.tensor([1 / gender_dict[key] for key in key_gender]).to(device)\n",
    "        bag_weights = torch.tensor([1 / bag_dict[key] for key in key_bag]).to(device)\n",
    "        hat_weights = torch.tensor([1 / hat_dict[key] for key in key_hat]).to(device)\n",
    "\n",
    "        return upper_weights, lower_weights, gender_weights, bag_weights, hat_weights\n",
    "\n",
    "\n",
    "class CustomRandomSampler(Sampler):\n",
    "\n",
    "    def __init__(self, dataset, replacement=False, batch_size=None):\n",
    "        self.data_source = dataset\n",
    "        self.replacement = replacement\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = list(range(len(self.data_source)))\n",
    "\n",
    "        number_iteration = len(indices) // self.batch_size\n",
    "\n",
    "        if not self.replacement:\n",
    "            indices = np.random.permutation(indices).tolist()\n",
    "\n",
    "        batch = []\n",
    "        index_seen = set()\n",
    "        deque = []\n",
    "        iteration = 1\n",
    "\n",
    "        for idx in indices:\n",
    "            if len(deque) > 0:\n",
    "                t = min(self.batch_size - len(batch), len(deque))\n",
    "                batch.extend(deque[:t])\n",
    "                del deque[:t]\n",
    "                if len(batch) == self.batch_size:\n",
    "                    deque.append(idx)\n",
    "\n",
    "            if len(batch) < self.batch_size:\n",
    "                batch.append(idx)\n",
    "\n",
    "            if len(batch) == self.batch_size:\n",
    "\n",
    "                for batch_sample_index, sample_index in enumerate(batch):\n",
    "                    _, labels = self.data_source[sample_index]\n",
    "\n",
    "                    for label_index, l in enumerate(labels):\n",
    "\n",
    "                        if l != -1:\n",
    "                            index_seen.add(label_index)\n",
    "                        elif l == -1 and label_index not in index_seen:\n",
    "\n",
    "                            deque.append(sample_index)\n",
    "\n",
    "                            # tentative = 0\n",
    "                            while(True):\n",
    "                                index_new_sample = np.random.choice(len(self.data_source))\n",
    "                                _, labels = self.data_source[index_new_sample]\n",
    "                                # tentative += 1\n",
    "                                if labels[label_index] != -1:\n",
    "                                    batch[batch_sample_index] = index_new_sample\n",
    "                                    break\n",
    "\n",
    "                yield batch\n",
    "\n",
    "                if iteration == number_iteration:\n",
    "                  break\n",
    "\n",
    "                iteration += 1\n",
    "                index_seen = set()\n",
    "                batch = []\n",
    "\n",
    "\n",
    "training_dataset = CustomImageDataset(training_image_paths, annotations_training_list, transform=data_transforms['train'])\n",
    "validation_dataset = CustomImageDataset(validation_image_paths, annotations_validation_list, transform=data_transforms['validation'])\n",
    "\n",
    "batch_size = 32\n",
    "num_batch = len(training_dataset) // batch_size\n",
    "sampler = CustomRandomSampler(dataset=training_dataset, batch_size=batch_size, replacement=False)\n",
    "\n",
    "train_dataloader = DataLoader(training_dataset, batch_sampler = sampler)\n",
    "val_dataloader = DataLoader(validation_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "print('num batch ', num_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T10:49:23.287984Z",
     "iopub.status.busy": "2024-02-09T10:49:23.287632Z",
     "iopub.status.idle": "2024-02-09T10:49:23.295257Z",
     "shell.execute_reply": "2024-02-09T10:49:23.294280Z",
     "shell.execute_reply.started": "2024-02-09T10:49:23.287954Z"
    },
    "id": "R7OP2B2H5YB3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ResNet50Backbone(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResNet50Backbone, self).__init__() \n",
    "\n",
    "        self.model = resnet50(pretrained=True)\n",
    "        self.model = torch.nn.Sequential(*list(self.model.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def freeze_all(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def unfreeze_last_layers(self, num_layers):\n",
    "        for param in list(self.model.parameters())[-num_layers:]:\n",
    "            param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T10:49:34.842916Z",
     "iopub.status.busy": "2024-02-09T10:49:34.842550Z",
     "iopub.status.idle": "2024-02-09T10:49:34.852970Z",
     "shell.execute_reply": "2024-02-09T10:49:34.851907Z",
     "shell.execute_reply.started": "2024-02-09T10:49:34.842884Z"
    },
    "id": "4RGm7t8A5YB4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionModule(nn.Module):\n",
    "    #https://github.com/luuuyi/CBAM.PyTorch\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(AttentionModule, self).__init__()\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.channel_attention  = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 16, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 16, in_channels, kernel_size=1, padding=0),\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_spatial = torch.cat([avg_out, max_out], dim=1)\n",
    "        x_spatial = self.spatial_attention(x_spatial)\n",
    "\n",
    "        avg_out = self.channel_attention(self.avg_pool(x))\n",
    "        max_out = self.channel_attention(self.max_pool(x))\n",
    "        x_channel = avg_out + max_out\n",
    "        x_channel = self.sigmoid(x_channel)\n",
    "        \n",
    "        out = x * x_channel * x_spatial\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T10:49:38.791760Z",
     "iopub.status.busy": "2024-02-09T10:49:38.791416Z",
     "iopub.status.idle": "2024-02-09T10:49:38.800361Z",
     "shell.execute_reply": "2024-02-09T10:49:38.799449Z",
     "shell.execute_reply.started": "2024-02-09T10:49:38.791732Z"
    },
    "id": "vXS49iyKviD6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(BinaryClassifier, self).__init__()\n",
    "\n",
    "    self.block1 = nn.Sequential(nn.Linear(2048, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(0.3))\n",
    "    self.block2 = nn.Sequential(nn.Linear(512, 1), nn.Sigmoid())\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.block1(x)\n",
    "    x = self.block2(x)\n",
    "    return x\n",
    "  \n",
    "\n",
    "class MultiClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "      super(MultiClassifier, self).__init__()\n",
    "\n",
    "      self.block1 = nn.Sequential(nn.Linear(2048, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(0.3))\n",
    "      self.block2 = nn.Sequential(nn.Linear(512, 11))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.block1(x)\n",
    "    x = self.block2(x)\n",
    "    return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T10:49:42.752322Z",
     "iopub.status.busy": "2024-02-09T10:49:42.751498Z",
     "iopub.status.idle": "2024-02-09T10:49:42.763129Z",
     "shell.execute_reply": "2024-02-09T10:49:42.762124Z",
     "shell.execute_reply.started": "2024-02-09T10:49:42.752288Z"
    },
    "id": "PBch_IfK5YB5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttributeRecognitionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_attributes):\n",
    "        super(AttributeRecognitionModel, self).__init__()\n",
    "\n",
    "        self.backbone = ResNet50Backbone()\n",
    "        self.attention_modules = nn.ModuleList([AttentionModule(in_channels=2048) for _ in range(num_attributes)]) \n",
    "        binary_classifier = [BinaryClassifier() for _ in range(3)]\n",
    "        multi_classifier = [MultiClassifier() for _ in range(2)]\n",
    "        self.classifiers = nn.ModuleList(multi_classifier + binary_classifier)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        pred_list=[]\n",
    "        attention_outputs = [attention(features) for attention in self.attention_modules]\n",
    "        \n",
    "        for att_output, classifier in zip(attention_outputs, self.classifiers):\n",
    "            flattened_output = att_output.view(att_output.size(0), -1)\n",
    "            pred = classifier(flattened_output)\n",
    "            pred_list.append(pred)\n",
    "            \n",
    "        return pred_list\n",
    "\n",
    "    def freeze_backbone_parameters(self):\n",
    "      self.backbone.freeze_all()\n",
    "\n",
    "    def unfreeze_parameters(self):\n",
    "        for param in self.attention_modules.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.classifiers.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def unfreeze_last_layer_backbone(self, num_layers):\n",
    "        self.backbone.unfreeze_last_layers(num_layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T10:49:47.515694Z",
     "iopub.status.busy": "2024-02-09T10:49:47.514927Z",
     "iopub.status.idle": "2024-02-09T10:49:47.527591Z",
     "shell.execute_reply": "2024-02-09T10:49:47.526429Z",
     "shell.execute_reply.started": "2024-02-09T10:49:47.515660Z"
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1706789233549,
     "user": {
      "displayName": "LORENZO MIGNONE",
      "userId": "02647048791547825809"
     },
     "user_tz": -60
    },
    "id": "OppXfSVLiMP6",
    "outputId": "c19a4843-8eb1-455a-84cb-715cb6ced2dd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class BinaryAsymmetricLoss(nn.Module):\n",
    "  # https://arxiv.org/abs/2009.14119\n",
    "\n",
    "  def __init__(self, gamma_neg: any, gamma_pos: any, eps: float = 1e-8, ignore_index = None) -> None:\n",
    "    global device\n",
    "    super(BinaryAsymmetricLoss, self).__init__()\n",
    "    self.gamma_neg = gamma_neg if isinstance(gamma_neg, torch.Tensor) else torch.tensor(gamma_neg)\n",
    "    self.gamma_pos = gamma_pos if isinstance(gamma_pos, torch.Tensor) else torch.tensor(gamma_pos)\n",
    "    self.gamma_neg = self.gamma_neg.to(device)\n",
    "    self.gamma_pos = self.gamma_pos.to(device)\n",
    "    self.eps = eps\n",
    "    self.ignore_index = ignore_index\n",
    "\n",
    "\n",
    "  def forward(self, prob: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    global device\n",
    "\n",
    "    # BINARY NORMALE\n",
    "    targets = targets.float().to(device)\n",
    "    \n",
    "    if self.ignore_index:\n",
    "      mask = torch.ones_like(targets, dtype=torch.bool)\n",
    "      mask[targets == self.ignore_index] = 0\n",
    "      targets = targets[mask]\n",
    "      prob = prob[mask]\n",
    "    \n",
    "    prob = prob.squeeze(1)\n",
    "    weight = torch.where(targets == 0, self.gamma_neg, self.gamma_pos).to(device)\n",
    "    loss = F.binary_cross_entropy(prob, targets, weight=weight).to(device)\n",
    "    return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T10:49:53.034623Z",
     "iopub.status.busy": "2024-02-09T10:49:53.033720Z",
     "iopub.status.idle": "2024-02-09T10:49:53.043993Z",
     "shell.execute_reply": "2024-02-09T10:49:53.042885Z",
     "shell.execute_reply.started": "2024-02-09T10:49:53.034588Z"
    },
    "id": "CC9UZLjCY3Df",
    "outputId": "46ea6f36-791b-4082-a617-745181e8cf38",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Accuracy():\n",
    "    \n",
    "    def __init__(self, threshold=0.5, is_binary=False, ignore_index=-1):\n",
    "        self.threshold = threshold\n",
    "        self.is_binary = is_binary\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def __call__(self, predictions, targets):\n",
    "        \n",
    "        if self.is_binary:\n",
    "            predictions = predictions.squeeze()\n",
    "            acc = (predictions > self.threshold) == targets.detach()\n",
    "            mask = targets != self.ignore_index\n",
    "            acc = acc[mask]\n",
    "            good_target = mask.float().sum()\n",
    "            acc = acc.float().sum()\n",
    "            return acc, good_target\n",
    "\n",
    "        predictions = F.softmax(predictions, dim=1)\n",
    "        _, prob_indicies = torch.max(predictions, dim=1)\n",
    "        mask = targets != self.ignore_index\n",
    "        acc = prob_indicies == targets.detach()\n",
    "        acc = acc[mask]\n",
    "        good_target = mask.float().sum()\n",
    "        acc = acc.float().sum()\n",
    "        return acc, good_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HY6T8r0ZY3Dg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# NUOVO ADDESTRAMENTO\n",
    "\n",
    "num_attributes = 5\n",
    "num_layers = 3\n",
    "\n",
    "model = AttributeRecognitionModel(num_attributes=num_attributes)\n",
    "model.freeze_backbone_parameters()\n",
    "model.unfreeze_last_layer_backbone(num_layers)\n",
    "model.unfreeze_parameters()\n",
    "\n",
    "upper_weights, lower_weights, gender_weights, bag_weights, hat_weights = CustomImageDataset.make_weights(training_dataset)\n",
    "\n",
    "loss_list = [nn.CrossEntropyLoss(weight=upper_weights, ignore_index=-1), nn.CrossEntropyLoss(weight=lower_weights, ignore_index=-1), BinaryAsymmetricLoss(ignore_index=-1, gamma_neg=gender_weights[0], gamma_pos=gender_weights[1]), BinaryAsymmetricLoss(ignore_index=-1, gamma_neg=bag_weights[0], gamma_pos=bag_weights[1]), BinaryAsymmetricLoss(ignore_index=-1, gamma_neg=hat_weights[0], gamma_pos=hat_weights[1])]\n",
    "\n",
    "accuracy_list = [Accuracy(is_binary=False), Accuracy(is_binary=False), Accuracy(is_binary=True), Accuracy(is_binary=True), Accuracy(is_binary=True)]\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T10:49:58.886123Z",
     "iopub.status.busy": "2024-02-09T10:49:58.885087Z",
     "iopub.status.idle": "2024-02-09T10:50:02.861289Z",
     "shell.execute_reply": "2024-02-09T10:50:02.860499Z",
     "shell.execute_reply.started": "2024-02-09T10:49:58.886086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ADDESTRAMENTO DA CHECKPOINT\n",
    "\n",
    "num_attributes = 5\n",
    "num_layers = 3\n",
    "\n",
    "path = os.path.join('/kaggle/input/modello/best_model.pth', 'model_checkpoint.pth')\n",
    "\n",
    "model = AttributeRecognitionModel(num_attributes=num_attributes)\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "model.freeze_backbone_parameters()\n",
    "model.unfreeze_last_layer_backbone(num_layers)\n",
    "model.unfreeze_parameters()\n",
    "\n",
    "upper_weights, lower_weights, gender_weights, bag_weights, hat_weights = CustomImageDataset.make_weights(training_dataset)\n",
    "\n",
    "loss_list = [nn.CrossEntropyLoss(weight=upper_weights, ignore_index=-1), nn.CrossEntropyLoss(weight=lower_weights, ignore_index=-1), BinaryAsymmetricLoss(ignore_index=-1, gamma_neg=gender_weights[0], gamma_pos=gender_weights[1]), BinaryAsymmetricLoss(ignore_index=-1, gamma_neg=bag_weights[0], gamma_pos=bag_weights[1]), BinaryAsymmetricLoss(ignore_index=-1, gamma_neg=hat_weights[0], gamma_pos=hat_weights[1])]\n",
    "\n",
    "accuracy_list = [Accuracy(is_binary=False), Accuracy(is_binary=False), Accuracy(is_binary=True), Accuracy(is_binary=True), Accuracy(is_binary=True)]\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T10:50:07.476253Z",
     "iopub.status.busy": "2024-02-09T10:50:07.475883Z"
    },
    "id": "xkGZXT2NY3Dg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "global device \n",
    "\n",
    "def one_epoch(model, criterion_list, optimizer, train_loader, val_loader, epoch_num, accuracy_list, num_batch):\n",
    "  model.cuda()\n",
    "  model.train()\n",
    "\n",
    "  task_acc = dict((i, []) for i in range(num_attributes))\n",
    "  train_loss = torch.tensor(0.0, dtype = torch.float32, device = device)\n",
    "  \n",
    "  for i, (images, labels) in tqdm(enumerate(train_loader), desc=\"epoch {} - train\".format(epoch_num)):\n",
    "\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda().long()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    o = model(images)\n",
    "\n",
    "    batch_loss = []\n",
    "    \n",
    "    for attr_index in range(num_attributes):\n",
    "      target = labels[:, attr_index]\n",
    "      attribute_predictions = o[attr_index]\n",
    "      loss = criterion_list[attr_index](attribute_predictions, target)\n",
    "      acc, good_target = accuracy_list[attr_index](attribute_predictions, target)\n",
    "      \n",
    "      batch_loss.append(loss)\n",
    "      task_acc[attr_index].append((acc.item(), good_target.item()))\n",
    "\n",
    "    aggregated_loss = sum(batch_loss).to(device)\n",
    "    train_loss += aggregated_loss\n",
    "    aggregated_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    del images\n",
    "    del labels\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  train_loss = (train_loss / num_batch).item()\n",
    "  task_acc = [sum(task_acc[i][0]) / sum(task_acc[i][1]) for i in range(num_attributes)]\n",
    "  train_accuracy = sum(task_acc) / num_attributes\n",
    "  \n",
    "  print(\"Training loss and accuracy : {:.7f}\\t{:.4f}\".format(train_loss, train_accuracy))\n",
    "  print(\"Task upper accuracy : \", task_acc[0])\n",
    "  print(\"Task lower accuracy : \", task_acc[1])\n",
    "  print(\"Task gender accuracy : \", task_acc[2])\n",
    "  print(\"Task bag accuracy : \", task_acc[3])\n",
    "  print(\"Task hat accuracy : \", task_acc[4])\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    val_loss = []\n",
    "    task_acc = dict((i, []) for i in range(num_attributes))\n",
    "    \n",
    "    for images, labels in tqdm(val_loader, desc=\"epoch {} - validation\".format(epoch_num)):\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda().long()\n",
    "\n",
    "      o = model(images)\n",
    "\n",
    "      batch_loss = []\n",
    "     \n",
    "      for attr_index in range(num_attributes):\n",
    "        target = labels[:, attr_index]\n",
    "        attribute_predictions = o[attr_index]\n",
    "\n",
    "        loss = criterion_list[attr_index](attribute_predictions, target)\n",
    "        acc, good_target = accuracy_list[attr_index](attribute_predictions, target)\n",
    "\n",
    "        batch_loss.append(loss)\n",
    "        task_acc[attr_index].append((acc.item(), good_target.item()))\n",
    "\n",
    "      aggregated_loss = sum(batch_loss)\n",
    "      val_loss.append(aggregated_loss)\n",
    "\n",
    "    task_acc = [sum(task_acc[i][0]) / sum(task_acc[i][1]) for i in range(num_attributes)]\n",
    "    val_accuracy = sum(task_acc) / num_attributes\n",
    "    val_loss = torch.stack(val_loss).mean().item() \n",
    "    \n",
    "    print(\"Validation loss and accuracy : {:.7f}\\t{:.4f}\".format(val_loss, val_accuracy))\n",
    "    print(\"Task upper accuracy : \", task_acc[0])\n",
    "    print(\"Task lower accuracy : \", task_acc[1])\n",
    "    print(\"Task gender accuracy : \", task_acc[2])\n",
    "    print(\"Task bag accuracy : \", task_acc[3])\n",
    "    print(\"Task hat accuracy : \", task_acc[4])\n",
    "\n",
    "  return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "EARLY_STOPPIMG_PATIENCE = 5\n",
    "early_stopping_counter = EARLY_STOPPIMG_PATIENCE\n",
    "\n",
    "epochs = 10\n",
    "min_val_loss = 1e10\n",
    "\n",
    "val_losses = torch.zeros(epochs)\n",
    "val_accuracies = torch.zeros(epochs)\n",
    "\n",
    "for e in range(epochs):\n",
    "  print(\"EPOCH {}\".format(e))\n",
    "\n",
    "  val_loss, val_accuracy = one_epoch(model, loss_list, optimizer, train_dataloader, val_dataloader, e, accuracy_list, num_batch)\n",
    "\n",
    "  val_losses[e] = val_loss\n",
    "  val_accuracies[e] = val_accuracy\n",
    "\n",
    "  if val_loss < min_val_loss:\n",
    "    min_val_loss = val_loss\n",
    "    early_stopping_counter = EARLY_STOPPIMG_PATIENCE \n",
    "    torch.save(model.state_dict(), os.path.join('/kaggle/working','par_models','best_model.pth'))\n",
    "    print(\"- saved best model: val_loss =\", val_loss, \"val_accuracy =\", val_accuracy)\n",
    "\n",
    "  if e>0: \n",
    "    if val_losses[e] > val_losses[e-1]:\n",
    "        early_stopping_counter -= 1\n",
    "    else:\n",
    "        early_stopping_counter = EARLY_STOPPIMG_PATIENCE \n",
    "\n",
    "  if early_stopping_counter == 0: \n",
    "      break\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4407648,
     "sourceId": 7571210,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4412783,
     "sourceId": 7580607,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4418298,
     "sourceId": 7590339,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
